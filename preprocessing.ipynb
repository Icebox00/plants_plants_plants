{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943f5476",
   "metadata": {},
   "source": [
    "**PREPROCESSING DATA**\n",
    "--\n",
    "Data comes from the PlantVillage dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e262e32",
   "metadata": {},
   "source": [
    "**ROADMAP**\n",
    "Before loading data into this Jupyter notebook:\n",
    "- Download raw data from PlantVillage. This data is already split into training and validation.\n",
    "\n",
    "After loading data into this Jupyter notebook:\n",
    "1. Inspect the split of the PlantVillage data.\n",
    "2. Use ImageDataGenerator to preprocess images into keras-compatible arrays. Recall that batch size is 32 and picture resolution is 256x256.\n",
    "3. Save preprocessed data as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26de9346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/d7/gzw_d5556yn5ldwq7lqn3kb40000gn/T/ipykernel_33154/3853911046.py\", line 3, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tensorflow/__init__.py\", line 49, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tensorflow/python/autograph/core/ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tensorflow/python/autograph/utils/__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tensorflow/python/autograph/utils/context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 62, in <module>\n",
      "    from tensorflow.python.framework import tensor as tensor_lib\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py\", line 35, in <module>\n",
      "    from tensorflow.python.framework import tensor_util\n",
      "  File \"/Users/shrutipanse/anaconda3/envs/csci1470/lib/python3.11/site-packages/tensorflow/python/framework/tensor_util.py\", line 39, in <module>\n",
      "    from tensorflow.python.framework import fast_tensor_util\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb236af",
   "metadata": {},
   "source": [
    "**CHECKING SPLIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bad14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in train set: 43444\n",
      "Total images in val set: 10861\n",
      "Train-Val Split: [0.8, 0.2]\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Checking number of files in each folder.\n",
    "    Note: Files were not pushed to git because they were too large. Instead, image files were kept on local device.\n",
    "'''\n",
    "import os\n",
    "\n",
    "train_dir = '../PlantVillage/train'\n",
    "val_dir = '../PlantVillage/val'\n",
    "\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "\n",
    "for class_name in os.listdir(val_dir):\n",
    "    # Get each class directory in the val directory\n",
    "    class_path = os.path.join(val_dir, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Count the number of files in the class directory and then add to the running sum\n",
    "    num_files = sum(1 for entry in os.scandir(class_path) if entry.is_file())\n",
    "    val_count += num_files\n",
    "\n",
    "for class_name in os.listdir(train_dir):\n",
    "    # Get each class directory in the train directory\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Count the number of files in the class directory and then add to the running sum\n",
    "    num_files = sum(1 for entry in os.scandir(class_path) if entry.is_file())\n",
    "    train_count += num_files\n",
    "\n",
    "print(f\"Total images in train set: {train_count}\")\n",
    "print(f\"Total images in val set: {val_count}\")\n",
    "\n",
    "total_count = train_count+val_count\n",
    "print(f\"Train-Val Split: {[train_count/total_count, val_count/total_count]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4820a2",
   "metadata": {},
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2591833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Creating data generators for training  and validations data.\n",
    "    Note: the steps to increase randomness for training were not stated by the paper.\n",
    "'''\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalize pixel values from [0, 255] to [0.0, 1.0]\n",
    "    rotation_range=20, # Randomly rotates images by up to 20 degrees\n",
    "    zoom_range=0.1, # Randomly zooms in or out by up to 10%\n",
    "    width_shift_range=0.1, # Randomly shifts image horizontally right or left by up to 10%\n",
    "    height_shift_range=0.1, # Randomly shifts image vertically up or down by up to 10%\n",
    ")\n",
    "\n",
    "# Do not want to randomize validation data\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ba4087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43444 images belonging to 38 classes.\n",
      "Found 10861 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Apply data generators to PlantVillage data.\n",
    "    Note: Preprocessed data is not saved after this point. \n",
    "\n",
    "Parameters as per paper:\n",
    "    image size = [256, 256]\n",
    "\n",
    "Each item in train_prepro is of size ([training size, 256, 256, 3], [training size, 38]), where the first element in the tuple is \n",
    "    the preprocessed image and the second is the class. The next cell lists out all of the one-hot encoded classes with their original\n",
    "    class names. Remember that there are 38 classes in total, and these classes are one-hot encoded.\n",
    "'''\n",
    "\n",
    "target_size = (256, 256)\n",
    "\n",
    "train_prepro = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=32, # For saving purposes, we don't use batch sizes and separate out the batches later\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_prepro = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb33bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9, 'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13, 'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17, 'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21, 'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25, 'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29, 'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33, 'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37}\n"
     ]
    }
   ],
   "source": [
    "'''  \n",
    "Printing out the indices for the encoded classes (just for reference)\n",
    "\n",
    "How to interpret these indices:\n",
    "    'Apple___Cedar_apple_rust: 2' means that the encoded label for the cedar apple rust disease image is [0 0 1 0 ... 0 0 0]\n",
    "'''\n",
    "print(train_prepro.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d46c4",
   "metadata": {},
   "source": [
    "**SAVING PREPROCESSED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb21d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_prepro) # train_images and train_labels are numpy arrays\n",
    "val_images, val_labels = next(val_prepro) # val_images and val_labels are numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c65ae88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43444*(1-0.125)\n",
    "train_images[0]\n",
    "train_labels[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84deb8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
