{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943f5476",
   "metadata": {},
   "source": [
    "**PREPROCESSING DATA**\n",
    "--\n",
    "Data comes from the PlantVillage dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e262e32",
   "metadata": {},
   "source": [
    "**ROADMAP**\n",
    "Before loading data into this Jupyter notebook:\n",
    "- Download raw data from PlantVillage. This data is already split into training and validation.\n",
    "\n",
    "After loading data into this Jupyter notebook:\n",
    "1. Inspect the split of the PlantVillage data.\n",
    "2. Use ImageDataGenerator to preprocess images into keras-compatible arrays. Recall that batch size is 32 and picture resolution is 256x256.\n",
    "3. Save preprocessed data as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26de9346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 13:52:25.947772: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb236af",
   "metadata": {},
   "source": [
    "**CHECKING SPLIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bad14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in train set: 32000\n",
      "Total images in val set: 8000\n",
      "Train-Val Split: [0.8, 0.2]\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Checking number of files in each folder.\n",
    "    Note: Files were not pushed to git because they were too large. Instead, image files were kept on local device.\n",
    "'''\n",
    "import os\n",
    "\n",
    "train_dir = '../PlantVillage/train'\n",
    "val_dir = '../PlantVillage/val'\n",
    "\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "\n",
    "for class_name in os.listdir(val_dir):\n",
    "    # Get each class directory in the val directory\n",
    "    class_path = os.path.join(val_dir, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Count the number of files in the class directory and then add to the running sum\n",
    "    num_files = sum(1 for entry in os.scandir(class_path) if entry.is_file())\n",
    "    val_count += num_files\n",
    "\n",
    "for class_name in os.listdir(train_dir):\n",
    "    # Get each class directory in the train directory\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Count the number of files in the class directory and then add to the running sum\n",
    "    num_files = sum(1 for entry in os.scandir(class_path) if entry.is_file())\n",
    "    train_count += num_files\n",
    "\n",
    "print(f\"Total images in train set: {train_count}\")\n",
    "print(f\"Total images in val set: {val_count}\")\n",
    "\n",
    "total_count = train_count+val_count\n",
    "print(f\"Train-Val Split: {[train_count/total_count, val_count/total_count]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4820a2",
   "metadata": {},
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2591833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Creating data generators for training  and validations data.\n",
    "    Note: the steps to increase randomness for training were not stated by the paper.\n",
    "'''\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalize pixel values from [0, 255] to [0.0, 1.0]\n",
    "    rotation_range=20, # Randomly rotates images by up to 20 degrees\n",
    "    zoom_range=0.1, # Randomly zooms in or out by up to 10%\n",
    "    width_shift_range=0.1, # Randomly shifts image horizontally right or left by up to 10%\n",
    "    height_shift_range=0.1, # Randomly shifts image vertically up or down by up to 10%\n",
    ")\n",
    "\n",
    "# Do not want to randomize validation data\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ba4087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32000 images belonging to 33 classes.\n",
      "Found 8000 images belonging to 33 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Apply data generators to PlantVillage data.\n",
    "    Note: Preprocessed data is not saved after this point. \n",
    "\n",
    "Parameters as per paper:\n",
    "    image size = [256, 256]\n",
    "\n",
    "Each item in train_prepro is of size ([training size, 256, 256, 3], [training size, 38]), where the first element in the tuple is \n",
    "    the preprocessed image and the second is the class. The next cell lists out all of the one-hot encoded classes with their original\n",
    "    class names. Remember that there are 38 classes in total, and these classes are one-hot encoded.\n",
    "'''\n",
    "\n",
    "target_size = (256, 256)\n",
    "\n",
    "train_prepro = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=32, # For saving purposes, we don't use batch sizes and separate out the batches later\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_prepro = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb33bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Cherry_(including_sour)___Powdery_mildew': 4, 'Cherry_(including_sour)___healthy': 5, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 6, 'Corn_(maize)___Common_rust_': 7, 'Corn_(maize)___Northern_Leaf_Blight': 8, 'Corn_(maize)___healthy': 9, 'Grape___Black_rot': 10, 'Grape___Esca_(Black_Measles)': 11, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 12, 'Grape___healthy': 13, 'Peach___Bacterial_spot': 14, 'Peach___healthy': 15, 'Pepper,_bell___Bacterial_spot': 16, 'Pepper,_bell___healthy': 17, 'Potato___Early_blight': 18, 'Potato___Late_blight': 19, 'Potato___healthy': 20, 'Strawberry___Leaf_scorch': 21, 'Strawberry___healthy': 22, 'Tomato___Bacterial_spot': 23, 'Tomato___Early_blight': 24, 'Tomato___Late_blight': 25, 'Tomato___Leaf_Mold': 26, 'Tomato___Septoria_leaf_spot': 27, 'Tomato___Spider_mites Two-spotted_spider_mite': 28, 'Tomato___Target_Spot': 29, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 30, 'Tomato___Tomato_mosaic_virus': 31, 'Tomato___healthy': 32}\n"
     ]
    }
   ],
   "source": [
    "'''  \n",
    "Printing out the indices for the encoded classes (just for reference)\n",
    "\n",
    "How to interpret these indices:\n",
    "    'Apple___Cedar_apple_rust: 2' means that the encoded label for the cedar apple rust disease image is [0 0 1 0 ... 0 0 0]\n",
    "'''\n",
    "print(train_prepro.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d46c4",
   "metadata": {},
   "source": [
    "**SAVING PREPROCESSED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb21d046",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_prepro) # train_images and train_labels are numpy arrays\n",
    "val_images, val_labels = next(val_prepro) # val_images and val_labels are numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ae88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "43444*(1-0.125)\n",
    "train_images[0]\n",
    "train_labels[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84deb8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
