{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943f5476",
   "metadata": {},
   "source": [
    "**PREPROCESSING DATA**\n",
    "--\n",
    "Data comes from the PlantVillage dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e262e32",
   "metadata": {},
   "source": [
    "**ROADMAP**\n",
    "Before loading data into this Jupyter notebook:\n",
    "- Download raw data from PlantVillage. This data is already split into training and validation.\n",
    "\n",
    "After loading data into this Jupyter notebook:\n",
    "1. Inspect the split of the PlantVillage data.\n",
    "2. Use ImageDataGenerator to preprocess images into keras-compatible arrays. Recall that batch size is 32 and picture resolution is 256x256.\n",
    "3. Save preprocessed data as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26de9346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-19 21:36:56.566613: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb236af",
   "metadata": {},
   "source": [
    "**SPLITTING**\n",
    "Not sure how to do this? Was thinking sklearn train_test_split but not sure how to do that with images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bad14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images in train set: 43444\n",
      "Total images in val set: 10861\n",
      "Train-Val Split: [0.8, 0.2]\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Checking number of files in each folder.\n",
    "    Note: Files were not pushed to git because they were too large. Instead, image files were kept on local device.\n",
    "'''\n",
    "import os\n",
    "\n",
    "train_dir = '../PlantVillage/train'\n",
    "val_dir = '../PlantVillage/val'\n",
    "\n",
    "train_count = 0\n",
    "val_count = 0\n",
    "\n",
    "for class_name in os.listdir(val_dir):\n",
    "    # Get each class directory in the val directory\n",
    "    class_path = os.path.join(val_dir, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Count the number of files in the class directory and then add to the running sum\n",
    "    num_files = sum(1 for entry in os.scandir(class_path) if entry.is_file())\n",
    "    val_count += num_files\n",
    "\n",
    "for class_name in os.listdir(train_dir):\n",
    "    # Get each class directory in the train directory\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    # Count the number of files in the class directory and then add to the running sum\n",
    "    num_files = sum(1 for entry in os.scandir(class_path) if entry.is_file())\n",
    "    train_count += num_files\n",
    "\n",
    "print(f\"Total images in train set: {train_count}\")\n",
    "print(f\"Total images in val set: {val_count}\")\n",
    "\n",
    "total_count = train_count+val_count\n",
    "print(f\"Train-Val Split: {[train_count/total_count, val_count/total_count]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4820a2",
   "metadata": {},
   "source": [
    "**PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2591833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Creating data generators for training  and validations data.\n",
    "    Note: the steps to increase randomness for training were not stated by the paper.\n",
    "'''\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalize pixel values from [0, 255] to [0.0, 1.0]\n",
    "    rotation_range=20, # Randomly rotates images by up to 20 degrees\n",
    "    zoom_range=0.1, # Randomly zooms in or out by up to 10%\n",
    "    width_shift_range=0.1, # Randomly shifts image horizontally right or left by up to 10%\n",
    "    height_shift_range=0.1, # Randomly shifts image vertically up or down by up to 10%\n",
    ")\n",
    "\n",
    "# Do not want to randomize validation data\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0ba4087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43444 images belonging to 38 classes.\n",
      "Found 10861 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Apply data generators to PlantVillage data.\n",
    "    Note: Preprocessed data is not saved after this point. \n",
    "\n",
    "Parameters as per paper:\n",
    "    image size = [256, 256]\n",
    "    batch size = 32\n",
    "\n",
    "To use this data in training and validation, pass train_prepro through model.fit (and the same for val_prepro). For example:\n",
    "    model.fit(train_prepro)\n",
    "\n",
    "Each item in train_prepro is of size ([batch size, 256, 256, 3], [batch_size, 38]), where the first element in the tuple is \n",
    "    the preprocessed image and the second is the class. The next cell lists out all of the one-hot encoded classes with their original\n",
    "    class names. Remember that there are 38 classes in total, and these classes are one-hot encoded.\n",
    "'''\n",
    "\n",
    "target_size = (256, 256)\n",
    "batch_size = 32\n",
    "\n",
    "train_prepro = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_prepro = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5eb33bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9, 'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13, 'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17, 'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21, 'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25, 'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29, 'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33, 'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37}\n"
     ]
    }
   ],
   "source": [
    "'''  \n",
    "Printing out the indices for the encoded classes (just for reference)\n",
    "\n",
    "How to interpret these indices:\n",
    "    'Apple___Cedar_apple_rust: 2' means that the encoded label for the cedar apple rust disease image is [0 0 1 0 ... 0 0 0]\n",
    "'''\n",
    "print(train_prepro.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45d46c4",
   "metadata": {},
   "source": [
    "**SAVING PREPROCESSED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21d046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
